"""
Discovery Orchestrator
Î¤ÏÎ­Ï‡ÎµÎ¹ ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ scrapers Ï€Î±ÏÎ¬Î»Î»Î·Î»Î± ÎºÎ±Î¹ Ï„Î± ÏƒÏ„Î­Î»Î½ÎµÎ¹ ÏƒÏ„Î·Î½ queue.

Î§ÏÎ®ÏƒÎ·:
    python -m bounty_hunter.discovery.orchestrator
"""
import asyncio
import logging
import os
from datetime import datetime

from .models.bounty import Bounty
from .queue.manager import BountyQueueManager
from .scrapers.bountycaster import BountyCasterScraper
from .scrapers.gitcoin import GitcoinScraper
from .scrapers.github_scraper import GitHubScraper
from .scrapers.dework_layer3 import DeworkScraper, Layer3Scraper

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s â€” %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("orchestrator")


class DiscoveryOrchestrator:
    """
    ÎšÎµÎ½Ï„ÏÎ¹ÎºÏŒÏ‚ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÏ„Î®Ï‚ Î³Î¹Î± Ï„Î¿ Discovery Layer.

    - Î¤ÏÎ­Ï‡ÎµÎ¹ scrapers Ï€Î±ÏÎ¬Î»Î»Î·Î»Î± (asyncio gather)
    - Î£Ï„Î­Î»Î½ÎµÎ¹ bounties ÏƒÏ„Î·Î½ queue Î¼Îµ dedup
    - Î•Ï€Î±Î½Î±Î»Î±Î¼Î²Î¬Î½ÎµÏ„Î±Î¹ ÎºÎ¬Î¸Îµ N Î»ÎµÏ€Ï„Î¬ (polling loop)
    """

    def __init__(self, config: dict):
        self.config = config
        self.queue = BountyQueueManager(
            redis_url=config.get("redis_url", "redis://localhost:6379")
        )
        self._scrapers_config = config.get("scrapers", {})
        self._poll_interval = config.get("poll_interval_minutes", 15) * 60
        self._run_count = 0

    def _build_scrapers(self) -> list:
        """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ scrapers Î²Î¬ÏƒÎµÎ¹ config."""
        scrapers = []
        cfg = self._scrapers_config

        # BountyCaster
        if api_key := cfg.get("bountycaster", {}).get("api_key") or os.getenv("NEYNAR_API_KEY"):
            scrapers.append(
                BountyCasterScraper(
                    api_key=api_key,
                    config=cfg.get("bountycaster", {}),
                )
            )
            logger.info("âœ… BountyCaster scraper enabled")
        else:
            logger.warning("âš ï¸  BountyCaster skipped â€” no NEYNAR_API_KEY")

        # Gitcoin
        scrapers.append(GitcoinScraper(config=cfg.get("gitcoin", {})))
        logger.info("âœ… Gitcoin scraper enabled")

        # GitHub
        if gh_token := cfg.get("github", {}).get("token") or os.getenv("GITHUB_TOKEN"):
            scrapers.append(
                GitHubScraper(
                    token=gh_token,
                    config=cfg.get("github", {}),
                )
            )
            logger.info("âœ… GitHub scraper enabled")
        else:
            logger.warning("âš ï¸  GitHub scraper skipped â€” no GITHUB_TOKEN")

        # Dework
        scrapers.append(DeworkScraper(config=cfg.get("dework", {})))
        logger.info("âœ… Dework scraper enabled")

        # Layer3
        scrapers.append(Layer3Scraper(config=cfg.get("layer3", {})))
        logger.info("âœ… Layer3 scraper enabled")

        return scrapers

    async def _run_scraper(self, scraper) -> list[Bounty]:
        """Î¤ÏÎ­Ï‡ÎµÎ¹ Î­Î½Î±Î½ scraper Î¼Îµ error handling."""
        try:
            bounties = await scraper.run()
            logger.info(f"[{scraper.SOURCE_NAME}] â†’ {len(bounties)} bounties found")
            return bounties
        except Exception as e:
            logger.error(f"[{scraper.SOURCE_NAME}] Scraper failed: {e}", exc_info=True)
            return []

    async def run_once(self) -> dict:
        """ÎˆÎ½Î±Ï‚ ÎºÏÎºÎ»Î¿Ï‚ discovery â€” Ï„ÏÎ­Ï‡ÎµÎ¹ ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ scrapers."""
        self._run_count += 1
        start = datetime.utcnow()
        logger.info(f"\n{'='*50}")
        logger.info(f"ğŸ” Discovery Run #{self._run_count} â€” {start.strftime('%Y-%m-%d %H:%M:%S')} UTC")
        logger.info(f"{'='*50}")

        scrapers = self._build_scrapers()

        # Î¤ÏÎ­Ï‡Î¿Ï…Î½ Ï€Î±ÏÎ¬Î»Î»Î·Î»Î± Î¼Îµ asyncio.gather
        results = await asyncio.gather(
            *[self._run_scraper(s) for s in scrapers],
            return_exceptions=False,
        )

        # Flatten
        all_bounties: list[Bounty] = []
        for batch in results:
            all_bounties.extend(batch)

        logger.info(f"\nğŸ“¦ Total bounties found: {len(all_bounties)}")

        # Push ÏƒÏ„Î·Î½ queue
        queue_stats = await self.queue.push_many(all_bounties)

        elapsed = (datetime.utcnow() - start).total_seconds()
        summary = {
            "run": self._run_count,
            "scrapers": len(scrapers),
            "total_found": len(all_bounties),
            "new_queued": queue_stats["new"],
            "duplicates": queue_stats["duplicates"],
            "elapsed_seconds": round(elapsed, 2),
            "queue_size": await self.queue.queue_size(),
            "bloom_filter": self.queue.stats["bloom_filter_count"],
        }

        logger.info(f"""
ğŸ“Š Run Summary:
   â”œâ”€ Scrapers run  : {summary['scrapers']}
   â”œâ”€ Bounties found: {summary['total_found']}
   â”œâ”€ New queued    : {summary['new_queued']} âœ…
   â”œâ”€ Duplicates    : {summary['duplicates']} ğŸ”
   â”œâ”€ Queue size    : {summary['queue_size']}
   â””â”€ Elapsed       : {summary['elapsed_seconds']}s
""")
        return summary

    async def run_forever(self):
        """
        Polling loop â€” Ï„ÏÎ­Ï‡ÎµÎ¹ ÎºÎ¬Î¸Îµ poll_interval_minutes.
        Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ 16 cores Ï„Î¿Ï… Ryzen 5950X Î¼Î­ÏƒÏ‰ asyncio.
        """
        await self.queue.connect()
        logger.info(f"ğŸš€ Starting Discovery Loop (every {self._poll_interval//60} min)")

        try:
            while True:
                await self.run_once()
                logger.info(f"ğŸ˜´ Sleeping {self._poll_interval//60} min until next run...")
                await asyncio.sleep(self._poll_interval)
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ Stopping Discovery Orchestrator...")
        finally:
            await self.queue.disconnect()


# ---------------------------------------------------------------------------
# Default config â€” override Î¼Îµ config.yaml Î® env vars
# ---------------------------------------------------------------------------

DEFAULT_CONFIG = {
    "redis_url": os.getenv("REDIS_URL", "redis://localhost:6379"),
    "poll_interval_minutes": int(os.getenv("POLL_INTERVAL_MIN", "15")),
    "scrapers": {
        "bountycaster": {
            "api_key": os.getenv("NEYNAR_API_KEY", ""),
            "min_reward_usd": 10,
            "max_results": 50,
        },
        "gitcoin": {
            "min_reward_usd": 20,
            "max_results": 50,
            "network": "1",   # Ethereum mainnet
        },
        "github": {
            "token": os.getenv("GITHUB_TOKEN", ""),
            "min_reward_usd": 0,
            "max_per_org": 15,
            "orgs": [
                "ethereum", "gitcoinco", "uniswap", "aave",
                "OpenZeppelin", "smartcontractkit", "thirdweb-dev",
            ],
        },
        "dework": {
            "min_reward_usd": 10,
            "max_results": 40,
        },
        "layer3": {
            "max_results": 30,
        },
    },
}


if __name__ == "__main__":
    orchestrator = DiscoveryOrchestrator(config=DEFAULT_CONFIG)
    asyncio.run(orchestrator.run_forever())
